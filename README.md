# FER-Model

## Overview
MEY is an application based on Deep Learning. This application can detect the user's expression by using facial recognition technology. With this technology MEY can detect user expressions and connect to the list of songs that we have offered and users can open the playlist via Youtube.
MEY was created with the aim of elevating the mood of the user and can make the user to adapt the song to the expression that has been detected by our application.

## Credit
The dataset that we use for the prediction of the built model is [DATASET](https://www.kaggle.com/datasets/jonathanoheix/face-expression-recognition-dataset).

Then the reference we used in building our model from Kaggle [Reference](https://www.kaggle.com/code/jonathanoheix/face-expression-recognition-with-deep-learning).


## Making Prediction Models (Machine Learning)
From the dataset there are 32,887 data and for this model we use 7 facial expressions which will produce output in the form of facial expression categories that are inputted in the form of anger, disgust, fear, happy, neutral, sad, and surprised. In general, we do data preprocessing, which is to divide the data for training and model validation. In this model we use 28,821 data samples for training and 7,066 data samples for validation. After that we build the model with tensorflow. Then the model will generate a predictive output of [REF](https://github.com/MEY-Mental-Education-Yes/MEY-Workflow/blob/main/Face_Expression_Recognition.ipynb).
The Machine Learning Path uses Jupyter Lab to build models and pre-implementation processes.
